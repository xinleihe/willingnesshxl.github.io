---
title: "Publications"
permalink: /publications/
author_profile: true
---


You can also find my publications on [Google Scholar](https://scholar.google.com/citations?user=6hZNEtoAAAAJ).





<!-- ### Preprint
<b><font color="#19B4F3">Node-Level Membership Inference Attacks Against Graph Neural Networks</font></b>
<br>**Xinlei He**, Rui Wen, Yixin Wu, Michael Backes, Yun Shen, Yang Zhang
<br><a class="btn btn-primary" href="https://arxiv.org/abs/2102.05429">arxiv</a> -->
<!-- <a href="https://arxiv.org/abs/2102.05429" class="btn--blue" target="_blank">arxiv</a> -->


### 2024

### <font size="3"><span style="color:rgb(0, 119, 181)">You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content</span></font>  
<font size="3"><b>Xinlei He</b>, Savvas Zannettou, Yun Shen, Yang Zhang; <i>S&P 2024</i></font>
[[paper]]() 

### <font size="3"><span style="color:rgb(0, 119, 181)">Test-Time Poisoning Attacks Against Test-Time Adaptation Models</span></font>  
<font size="3">Tianshuo Cong, <b>Xinlei He</b>, Yun Shen, Yang Zhang; <i>S&P 2024</i></font>
[[paper]]() 

### 2023

### <font size="3"><span style="color:rgb(0, 119, 181)">Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes From Text-To-Image Models</span></font>  
<font size="3">Yiting Qu, Xinyue Shen, <b>Xinlei He</b>, Michael Backes, Savvas Zannettou, Yang Zhang; <i>CCS 2023</i></font>
[[paper]]() 

### <font size="3"><span style="color:rgb(0, 119, 181)">Data Poisoning Attacks Against Multimodal Encoders</span></font>  
<font size="3">Ziqing Yang, <b>Xinlei He</b>, Zheng Li, Michael Backes, Mathias Humbert, Pascal Berrang, Yang Zhang; <i>ICML 2023</i></font>
[[paper]]() 

### <font size="3"><span style="color:rgb(0, 119, 181)">Generated Graph Detection</span></font>  
<font size="3">Yihan Ma, Zhikun Zhang, Ning Yu, <b>Xinlei He</b>, Michael Backes, Yun Shen, Yang Zhang; <i>ICML 2023</i></font>
[[paper]]() 

### <font size="3"><span style="color:rgb(0, 119, 181)">Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image Encoders</span></font>  
<font size="3">Zeyang Sha, <b>Xinlei He</b>, Ning Yu, Michael Backes, Yang Zhang; <i>CVPR 2023</i></font>
[[paper]]() 

### <font size="3"><span style="color:rgb(0, 119, 181)">A Plot is Worth a Thousand Words: Model Information Stealing Attacks via Scientific Plots</span></font>  
<font size="3">Boyang Zhang, <b>Xinlei He</b>, Yun Shen, Tianhao Wang, Yang Zhang; <i>USENIX Security 2023</i></font>
[[paper]]() 

### <font size="3"><span style="color:rgb(0, 119, 181)">On the Evolution of (Hateful) Memes by Means of Multimodal Contrastive Learning</span></font>  
<font size="3">Yiting Qu, <b>Xinlei He</b>, Shannon Pierson, Michael Backes, Yang Zhang, Savvas Zannettou; <i>S&P 2023</i></font>
[[paper]](https://arxiv.org/abs/2212.06573)
[[code]](https://github.com/YitingQu/meme-evolution)

### <font size="3"><span style="color:rgb(0, 119, 181)">MGTBench: Benchmarking Machine-Generated Text Detection</span></font>  
<font size="3"><b>Xinlei He</b>, Xinyue Shen, Zeyuan Chen, Michael Backes, Yang Zhang</font>
[[paper]](https://arxiv.org/abs/2303.14822)
[[code]](https://github.com/xinleihe/MGTBench)

### 2022

### <font size="3"><span style="color:rgb(0, 119, 181)">Semi-Leak: Membership Inference Attacks Against Semi-supervised Learning</span></font>  
<font size="3"><b>Xinlei He</b>, Hongbin Liu, Neil Zhenqiang Gong, Yang Zhang; <i>ECCV 2022</i></font>
<!-- [[paper]]()  -->


### <font size="3"><span style="color:rgb(0, 119, 181)">SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained Encoders</span></font>  
<font size="3">Tianshuo Cong, <b>Xinlei He</b>, Yang Zhang; <i>CCS 2022</i></font>
[[paper]](https://arxiv.org/abs/2201.11692) 

<!-- <a href="" class="btn btn-primary">code</a> -->
<!-- [pdf](){: .btn--danger}{:target="_blank"} [arxiv](https://arxiv.org/abs/2201.11692){: .btn--danger}{:target="_blank"} [code](){: .btn--danger}{:target="_blank"} -->


### <font size="3"><span style="color:rgb(0, 119, 181)">Auditing Membership Leakages of Multi-Exit Networks</span></font>  
<font size="3">Zheng Li, Yiyong Liu, <b>Xinlei He</b>, Ning Yu, Michael Backes, Yang Zhang; <i>CCS 2022</i></font>  



### <font size="3"><font size="3"><span style="color:rgb(0, 119, 181)">Model Stealing Attacks Against Inductive Graph Neural Networks</span></font>  
<font size="3">Yun Shen*, <b>Xinlei He*</b>, Yufei Han, Yang Zhang (* Equal Contribution); <i>S&P 2022</i></font>  
[[paper]](https://arxiv.org/abs/2112.08331)
[[code]](https://github.com/xinleihe/GNNStealing)




### <font size="3"><span style="color:rgb(0, 119, 181)">ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models</span></font>  
<font size="3">Yugeng Liu, Rui Wen, <b>Xinlei He</b>, Ahmed Salem, Zhikun Zhang, Michael Backes, Emiliano De Cristofaro, Mario Fritz, Yang Zhang; <i>USENIX Security 2022</i></font>  
[[paper]](http://yangzhangalmo.github.io/papers/USENIXSECURITY22-MLDoctor.pdf)
[[code]](https://github.com/liuyugeng/ML-Doctor)


### <font size="3"><font size="3"><span style="color:rgb(0, 119, 181)">On Xing Tian and the Perseverance of Anti-China Sentiment Online</span></font>  
<font size="3">Xinyue Shen, <b>Xinlei He</b>, Michael Backes, Jeremy Blackburn, Savvas Zannettou, Yang Zhang; <i>ICWSM 2022</i></font>  
[[paper]](http://yangzhangalmo.github.io/papers/ICWSM22.pdf)



### 2021

### <font size="3"><span style="color:rgb(0, 119, 181)">Quantifying and Mitigating Privacy Risks of Contrastive Learning</span></font>  
<font size="3"><b>Xinlei He</b>, Yang Zhang; <i>CCS 2021</i></font> 
[[paper]](http://yangzhangalmo.github.io/papers/CCS21-ContrastivePrivacy.pdf)
[[code]](https://github.com/xinleihe/ContrastiveLeaks)


### <font size="3"><span style="color:rgb(0, 119, 181)">Stealing Links from Graph Neural Networks</span></font>  
<font size="3"><b>Xinlei He</b>, Jinyuan Jia, Michael Backes, Neil Zhenqiang Gong, Yang Zhang; <i>USENIX Security 2021</i></font> 
[[paper]](https://arxiv.org/abs/2005.02131)
[[code]](https://github.com/xinleihe/link_stealing_attack)



### <font size="3"><span style="color:rgb(0, 119, 181)">Trimming Mobile Applications for Bandwidth-Challenged Networks in Developing Regions</span></font>  
<font size="3">Qinge Xie, Qingyuan Gong, <b>Xinlei He</b>, Yang Chen, Xin Wang, Haitao Zheng, Ben Y. Zhao; <i>IEEE Transactions on Mobile Computing (TMC)</i></font>
[[paper]](https://arxiv.org/abs/1912.01328)


### <font size="3"><span style="color:rgb(0, 119, 181)">DatingSec: Detecting Malicious Accounts in Dating Apps Using a Content-Based Attention Network</span></font>  
<font size="3"><b>Xinlei He</b>, Qingyuan Gong, Yang Chen, Yang Zhang, Xin Wang, Xiaoming Fu; <i>IEEE Transactions on Dependable and Secure Computing (TDSC)</i></font>
[[paper]](https://ieeexplore.ieee.org/document/9384217)


### Prior to PhD:

### <font size="3"><span style="color:rgb(0, 119, 181)">Cross-Site Prediction on Social Influence for Cold-Start Users in Online Social Networks</span></font>  
<font size="3">Qingyuan Gong, Yang Chen, <b>Xinlei He</b>, Yu Xiao, Pan Hui, Xin Wang, Xiaoming Fu; <i>ACM Transactions on the Web (TWEB)</i></font>
[[paper]](https://dl.acm.org/doi/10.1145/3409108)

### <font size="3"><span style="color:rgb(0, 119, 181)">DeepScan: Exploiting Deep Learning for Malicious Account Detection in Location-Based Social Networks</span></font>  
<font size="3">Qingyuan Gong, Yang Chen, <b>Xinlei He</b>, Zhou Zhuang, Tianyi Wang, Hong Huang, Xin Wang, Xiaoming Fu; <i>IEEE Communications Magazine</i></font>  
[[paper]]((https://user.informatik.uni-goettingen.de/~ychen/papers/DeepScan-COMMAG18.pdf)

